# dl_dz_1

## Эксперимент 1

| Training epochs | Val Loss | Test Loss | Test ROC-AUC |
| --------------- | -------- | --------- | ------------ |
|        30       |  0.1926  |  0.1857   |    0.9320    |


Модель довольно долго сходится, но при этом все равно в итоге достигает хороших значений метрики на тесте. Оптимальное кол-во эпох выбрал равным 30, т.к. после 30 эпохи лосс модели на валидации пошел на спад.

## Эксперимент 2

| Training epochs | Val Loss | Test Loss | Test ROC-AUC |
| --------------- | -------- | --------- | ------------ |
|        30       |  0.2305  |   0.1859   |    0.9331   |

Модель сходится медленно на валидации (из-за того, что архитектура тяжелее), при этом тестовые метрики получились лучше.


## Эксперимент 3
| Training epochs | Val Loss | Test Loss | Test ROC-AUC |
| --------------- | -------- | --------- | ------------ |
|        19       |  0.1881  |   0.1978  |    0.9239    |


Модель сходится быстрее, чем предудыщие две, но результат у нее хуже, мое предположение, что это связано с тем, что используется простейший оптимизатор + не подбирается подходящий лр

## Эксперимент 4

| Dropout | Val Loss | Test Loss | Test ROC-AUC 
| ------- | -------- | --------- | ------------ |
|  0.01   |  0.1909  |   0.1838  |    0.9320    |
|  0.1    |  0.1901  |   0.1836  |    0.9322    |
|  0.2    |  0.1903  |   0.1837  |    0.9324    |
|  0.5    |  0.1914  |   0.1844  |    0.9323    |
|  0.9    |  0.2022  |   0.1928  |    0.9295    |

Слишком большие значения дропаута могут приводить к худшим результатам, т.к. модель не использует все свои нейроны, слишком маленькое значение дропаута может не быть достаточным для борьбы с переобучением и не давать прироста качества, т.е. оптимальное значение находится в пределах 0.5

## Эксперимент 5

| Lr   | Weight Decay|Val Loss | Test Loss | Test ROC-AUC 
| --   | ------------- |-------- | --------| ------------ |
| 0.1  |  0.1          |  0.3049 |  0.2938 |    0.8859    |
| 0.1  | 0.01          |  0.2186 |  0.2096 |    0.9209    |
| 0.1  | 0.001         |  0.1865 |  0.1824 |    0.9323    |
| 0.05 |  0.1          |  0.2999 |  0.3032 |    0.8869    |
| 0.05 | 0.01          |  0.2158 |  0.2069 |    0.9218    |
| 0.05 | 0.001         |  0.1855 |  0.1788 |    0.9331    |
| 0.01 |  0.1          |  0.2598 |  0.3012 |    0.8883    |
| 0.01 | 0.01          |  0.2231 |  0.2126 |    0.9214    |
| 0.01 | 0.001         |  0.1861 |  0.1793 |    0.9325    |


Оптимальна пара - (0.001, 0.05)

При бОльших лямбда (0.1) модель недообучается следовательно показывает гораздо худшие результаты, при большом лр (0.1) модель также сходится гораздо хуже, что приводит к плохому качеству и высокому лоссу на тесте и валидации.


P.S все эксперименты, графики лоссов и т.д. в ноутбуке dl_dz_1.ipynb
